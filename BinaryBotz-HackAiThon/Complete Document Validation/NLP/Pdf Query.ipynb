{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db509fc4-21bf-4b3c-9f8d-5886bb624c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LogaSanjeev\\anaconda3\\envs\\base-py\\Lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted details from the death certificate in a structured list with one detail per line:\n",
      "\n",
      "1. **Name:** Jaswinder Kaur\n",
      "2. **Permanent Address:** H no. 246-A Model town extension, Ludhiana (Pb)\n",
      "3. **Father's Name:** Ratan Singh\n",
      "4. **Nationality:** Indian\n",
      "5. **Sex:** Female\n",
      "6. **Date of Death:** 14/12/2023\n",
      "7. **Registration No.:** 65\n",
      "8. **Place of Death:** Ludhiana\n",
      "9. **Date of Registration:** 13/02/2024\n",
      "Extracted Information:\n",
      "\n",
      "Here are the extracted details from the death certificate in a structured list with one detail per line:\n",
      "\n",
      "1. **Name:** Jaswinder Kaur\n",
      "2. **Permanent Address:** H no. 246-A Model town extension, Ludhiana (Pb)\n",
      "3. **Father's Name:** Ratan Singh\n",
      "4. **Nationality:** Indian\n",
      "5. **Sex:** Female\n",
      "6. **Date of Death:** 14/12/2023\n",
      "7. **Registration No.:** 65\n",
      "8. **Place of Death:** Ludhiana\n",
      "9. **Date of Registration:** 13/02/2024\n",
      "Jaswinder KaurFemaleNoneNone.None.Ratan SinghNone.14/12/2023None.H no. 246-A Model town extension, Ludhiana (Pb)NoneLudhiana\n",
      "Extracted answers saved to answers.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "FILEPATH = \"./Image to Pdf Converter/output.pdf\"\n",
    "LOCAL_MODEL = \"llama3.1\"\n",
    "\n",
    "# Set up the language model without any memory or retrieval chain\n",
    "llm = Ollama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=LOCAL_MODEL,\n",
    "    verbose=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "# Load PDF and extract text (assume one-page certificate)\n",
    "loader = PyPDFLoader(FILEPATH)\n",
    "data = loader.load()\n",
    "pdf_text = \"\".join([doc.page_content for doc in data])\n",
    "\n",
    "extract_template = \"\"\"You are an AI assistant that extracts precise information from a death certificate.\n",
    "Do not assume answers if the certificate does not explicitly provide them.\n",
    "Check for every minute detail in the provided certificate.\n",
    "Return the extracted details in a structured list with one detail per line.\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Extracted Details:\"\"\"\n",
    "\n",
    "extract_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=extract_template,\n",
    ")\n",
    "\n",
    "# Use only the PDF text to extract details\n",
    "extracted_data_str = llm.invoke(extract_prompt.format(context=pdf_text)).strip()\n",
    "\n",
    "print(\"\\nExtracted Information:\\n\")\n",
    "print(extracted_data_str)\n",
    "\n",
    "qa_template = \"\"\"You are an AI assistant. Based solely on the following extracted details:\n",
    "{extracted_details}\n",
    "\n",
    "For each question, provide an answer exactly as it is stated in the extracted details. Do not infer or assume any details that are not explicitly mentioned.\n",
    "If the detail is not explicitly stated, simply answer \"None\".\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"extracted_details\", \"question\"],\n",
    "    template=qa_template,\n",
    ")\n",
    "\n",
    "# Simplified keys for JSON storage and updated Residential Address question\n",
    "questions_mapping = {\n",
    "    \"Name\": \"What is the name of the dead person?\",\n",
    "    \"Gender\": \"What is the gender of the dead person?\",\n",
    "    \"Age\": \"What is the age of the dead person?\",\n",
    "    \"Spouse Name\": \"What is the wife's/husband's name of the dead person?\",\n",
    "    \"Mother's Name\": \"What is the mother's name of the dead person?\",\n",
    "    \"Father's Name\": \"What is the father's name of the dead person?\",\n",
    "    \"Date of Birth\": \"What is the date of birth of the dead person?\",\n",
    "    \"Date of Death\": \"What is the date of death of the dead person?\",\n",
    "    \"Address at Time of Death\": \"What is the address of the dead person at the time of death? Answer only if address at the time of death is explicitly mentioned becuase permanent address might not be same as address at the time of death in some cases; otherwise, answer 'None'.\",\n",
    "    \"Residential Address\": \"What is the dead person's residential address? Answer only if a distinct permanent or residential address is explicitly mentioned; otherwise, answer 'None'.\",\n",
    "    \"Cause of Death\": \"What is the cause of death?\",\n",
    "    \"Place of Death\": \"What is the place of death?\",\n",
    "}\n",
    "\n",
    "answers_dict = {}\n",
    "\n",
    "# Ask each question using only the extracted details as context\n",
    "for key, question in questions_mapping.items():\n",
    "    response = llm.invoke(\n",
    "        qa_prompt.format(extracted_details=extracted_data_str, question=question)\n",
    "    ).strip()\n",
    "    \n",
    "    # Normalize responses that indicate missing data\n",
    "    if not response or any(term in response.lower() for term in [\"none\", \"not mentioned\", \"no information\"]):\n",
    "        answers_dict[key] = \"None\"\n",
    "    else:\n",
    "        answers_dict[key] = response\n",
    "\n",
    "# Save extracted answers to JSON\n",
    "with open(\"answers.json\", \"w\") as json_file:\n",
    "    json.dump(answers_dict, json_file, indent=4)\n",
    "\n",
    "print(\"\\nExtracted answers saved to answers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b519a-481a-4483-8fd3-386b051f0483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
