{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-23T14:03:14.111606Z",
     "start_time": "2025-02-23T14:02:41.654020Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import ollama\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "with open(r'path\\to\\model\\fraud_ensemble.pkl', 'rb') as f:\n",
    "    gnn_state_dict, xgb_model, scaler, label_encoder = pickle.load(f)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_dim)\n",
    "        self.conv2 = GATConv(hidden_dim, 8)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class ModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model, edge_index):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, x):\n",
    "        data = Data(x=x, edge_index=self.edge_index)\n",
    "        return self.model(data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_features = 4\n",
    "num_classes = 2\n",
    "\n",
    "gnn_model = GNN(num_features=num_features, hidden_dim=128, num_classes=num_classes).to(device)\n",
    "gnn_model.load_state_dict(gnn_state_dict)\n",
    "gnn_model.eval()\n",
    "\n",
    "user_input = json.loads(input(\"Enter the input as a JSON string: \"))\n",
    "\n",
    "feature_values = np.array([[user_input[\"ASSURED_AGE\"], int(user_input[\"POLICY SUMASSURED\"].replace(\",\", \"\")),\n",
    "                           int(user_input[\"Premium\"].replace(\",\", \"\")), int(user_input[\"Annual Income\"].replace(\",\", \"\"))]])\n",
    "scaled_features = scaler.transform(feature_values)\n",
    "\n",
    "node_features = torch.tensor(scaled_features, dtype=torch.float).to(device)\n",
    "dummy_edge_index = torch.tensor([[0], [0]], dtype=torch.long).to(device)\n",
    "data = Data(x=node_features, edge_index=dummy_edge_index)\n",
    "\n",
    "with torch.no_grad():\n",
    "    gnn_logits = gnn_model(data)\n",
    "    gnn_pred = torch.argmax(gnn_logits, dim=1).item()\n",
    "\n",
    "xgb_pred = xgb_model.predict(scaled_features)[0]\n",
    "\n",
    "final_pred = xgb_pred if xgb_pred == gnn_pred else xgb_pred\n",
    "\n",
    "xgb_feature_importance = xgb_model.feature_importances_\n",
    "feature_names = [\"ASSURED_AGE\", \"POLICY SUMASSURED\", \"Premium\", \"Annual Income\"]\n",
    "important_features = sorted(zip(feature_names, xgb_feature_importance),\n",
    "                          key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "wrapped_model = ModelWrapper(gnn_model, dummy_edge_index)\n",
    "ig = IntegratedGradients(wrapped_model)\n",
    "baseline = torch.zeros_like(node_features)\n",
    "target = torch.tensor([final_pred], dtype=torch.long).to(device)\n",
    "attributions = ig.attribute(node_features, target=target, baselines=baseline)\n",
    "gnn_attr = attributions.cpu().detach().numpy()\n",
    "\n",
    "explanation = {\n",
    "    \"Final Prediction\": \"Fraud\" if final_pred == 1 else \"Legitimate\",\n",
    "    \"Top Features\": [feat[0] for feat in important_features],\n",
    "    \"Feature Importance (XGB)\": xgb_feature_importance.tolist(),\n",
    "    \"Feature Importance (GNN)\": gnn_attr.tolist()\n",
    "}\n",
    "\n",
    "llama_prompt = f\"\"\"\n",
    "Analyze the following insurance claim for fraud risk and explain the influencing factors:\n",
    "\n",
    "Claim Details:\n",
    "{json.dumps(user_input, indent=4)}\n",
    "\n",
    "Model Prediction: {explanation['Final Prediction']}\n",
    "Top Risk Factors: {', '.join(explanation['Top Features'])}\n",
    "\n",
    "Feature Importance:\n",
    "- XGBoost Analysis: {explanation['Feature Importance (XGB)']}\n",
    "- GNN Analysis: {explanation['Feature Importance (GNN)']}\n",
    "\n",
    "Calculate the risk contribution of all features and provide a detailed risk score and explanation. Recalculate the claim result based on the risk score.\n",
    "Mainly consider the Fraud Category feature into consideration.\n",
    "\n",
    "The explanation part should only mention the feature contribution determined logically by you not from the model.Dont return the output from the model.You consider them as additional information and calculate the risk scores and provide output based on the risk score boundaries.\n",
    "\n",
    "Output in the following format:\n",
    "Claim Result: Fraud/Legitimate/Potential Risk\n",
    "Risk Score: #score#(in percent)\n",
    "Fraud Category: (if fraud / potential risk)\n",
    "Explanation: What contributed to the result (mention features if fraud)\n",
    "Final verdict: Alert insurance agent to cross check else return claim can be approved\n",
    "\n",
    "Risk Score Boundaries:\n",
    "- Below 0.3: legitimate\n",
    "- 0.3 to 0.6: potential risk\n",
    "- Above 0.6: fraud\n",
    "\n",
    "Dont visualize your calculating steps,Just provide the final output(refer the output format above).\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI that explains fraud detection decisions.\"},\n",
    "    {\"role\": \"user\", \"content\": llama_prompt}\n",
    "]\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.1\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"\\n### Fraud Detection Explanation ###\\n\")\n",
    "print(response['message']['content'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fraud Detection Explanation ###\n",
      "\n",
      "Claim Result: Potential Risk\n",
      "Risk Score: 62%\n",
      "Fraud Category: Identity Theft\n",
      "Explanation: The high premium of ₹5,00,000 and policy sum assured of ₹50,00,000 in combination with an unemployed assured (ASSURED_AGE = 45) suggests that the claim may be fraudulent. Furthermore, the policy term and payment term being the same at 5 years implies that the assured might not have a regular income, making it difficult to pay premiums. The \"Identity Theft\" fraud category also supports this conclusion.\n",
      "Final verdict: Alert insurance agent to cross check before approving the claim.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T12:52:50.120445Z",
     "start_time": "2025-02-23T12:52:50.117080Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cad4cd7f36b505de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "86ad11aaa00bd979"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
